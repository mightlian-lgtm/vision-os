import { GoogleGenAI, Type } from "@google/genai";
import { StructuredResponse, UserContext } from "../types";

// FIX: Use process.env.API_KEY as per the coding guidelines. This resolves the TypeScript error.
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const MODEL_NAME = 'gemini-3-flash-preview';

// --- Lightweight Detection for Periodic Modes ---
export const detectSubject = async (imageBase64: string, isFullScreen: boolean): Promise<string> => {
    const cleanImage = imageBase64.split(',')[1] || imageBase64;
    const prompt = isFullScreen
      ? "Describe the overall activity or application window in this full-screen image. Return ONLY a short phrase (max 4 words). No punctuation."
      : "Identify the main single object or UI element in this cropped image. Return ONLY the name (max 3 words). No punctuation.";
    try {
        const response = await ai.models.generateContent({
            model: MODEL_NAME,
            contents: {
                parts: [
                    { text: prompt },
                    { inlineData: { mimeType: 'image/jpeg', data: cleanImage } }
                ]
            }
        });
        return response.text?.trim() || "unknown";
    } catch (e) {
        console.error("Subject detection failed:", e);
        return "unknown";
    }
}

// --- Main Analysis ---
export const analyzeContext = async (
  userContext: UserContext,
  fullImageBase64: string,
  cropImageBase64: string | null, // Null for Mode 1
  isConfirmationRequest: boolean = false
): Promise<StructuredResponse> => {
  
  const cleanFull = fullImageBase64.split(',')[1] || fullImageBase64;
  const cleanCrop = cropImageBase64 ? (cropImageBase64.split(',')[1] || cropImageBase64) : null;

  let prompt = "";
  let responseSchema: any = {};
  let parts: any[] = [{ text: "" }, { inlineData: { mimeType: 'image/jpeg', data: cleanFull } }];
  if (cleanCrop) {
    parts.push({ inlineData: { mimeType: 'image/jpeg', data: cleanCrop } });
  }

  // --- Mode-based Prompt Routing ---
  switch (userContext.mode) {
    case 1: // FOCUS MODE
      if (isConfirmationRequest) {
          prompt = `ä½ æ˜¯ä¸€ä¸ªâ€œä¸“æ³¨æ¨¡å¼â€AIã€‚ç”¨æˆ·é•¿æ—¶é—´ä¸“æ³¨äºåŒä¸€å±å¹•ã€‚è¿™æ˜¯å¦æ˜¯å¼€å¯ä¸“æ³¨æ¨¡å¼çš„å¥½æ—¶æœºï¼Ÿè¯·æä¾›ä¸€ä¸ªè¯¢é—®æ ‡é¢˜å’Œç®€çŸ­ç†ç”±ã€‚`;
          responseSchema = {
              type: Type.OBJECT, properties: {
                  title: { type: Type.STRING, description: "è¯¢é—®æ˜¯å¦å¼€å¯ä¸“æ³¨æ¨¡å¼çš„æ ‡é¢˜ + Emoji" },
                  insight: { type: Type.STRING, description: "ç®€çŸ­çš„ç†ç”±" },
                  isConfirmation: { type: Type.BOOLEAN, description: "Always true" }
              }, required: ["title", "insight", "isConfirmation"]
          };
      } else {
          prompt = `ç”¨æˆ·å·²ç¡®è®¤è¿›å…¥â€œä¸“æ³¨æ¨¡å¼â€ã€‚æ ¹æ®ä»–ä»¬çš„ä»»åŠ¡â€œ${userContext.task}â€ï¼Œæ¨èä¸è¶…è¿‡3ä¸ªæœ‰ç”¨çš„ç³»ç»Ÿå·¥å…·æ¥å¸®åŠ©ä»–ä»¬ä¿æŒä¸“æ³¨ã€‚å·¥å…·åå¿…é¡»æ˜¯ 'Recording', 'Memo', 'Camera', 'Calculator' ä¸­çš„ä¸€ä¸ªã€‚`;
          responseSchema = {
              type: Type.OBJECT, properties: {
                  title: { type: Type.STRING, description: "â€œä¸“æ³¨å·¥å…·ç®± ğŸ§˜â€" },
                  insight: { type: Type.STRING, description: "é¼“åŠ±çš„è¯è¯­" },
                  recommendations: { type: Type.ARRAY, items: { type: Type.STRING }, description: "å·¥å…·ååˆ—è¡¨" }
              }, required: ["title", "insight", "recommendations"]
          };
      }
      break;

    case 2: // FLUENT MODE
        prompt = `ä½ æ˜¯ä¸€ä¸ªâ€œæµç•…æ¨¡å¼â€AIï¼Œé¢„æµ‹ç”¨æˆ·åœ¨æœ‰è§„å¾‹æµç¨‹ä»»åŠ¡ä¸­çš„ä¸‹ä¸€æ­¥ã€‚ä»»åŠ¡: ${userContext.task}ã€‚æ ¹æ®å…¨å±€å’Œå±€éƒ¨ç”»é¢ï¼Œåˆ¤æ–­ç”¨æˆ·å½“å‰é˜¶æ®µå¹¶æä¾›ä¸‹ä¸€æ­¥æœ€æœ‰ç”¨çš„æ“ä½œç»„åˆ(é“¾æ¥ã€æ–‡æœ¬ã€å·¥å…·ç­‰)ã€‚`;
        responseSchema = {
            type: Type.OBJECT, properties: {
                title: { type: Type.STRING, description: "è¯¢é—®æ˜¯å¦éœ€è¦æ‰§è¡Œä¸‹ä¸€æ­¥çš„æ ‡é¢˜ + Emoji" },
                insight: { type: Type.STRING, description: "å¯¹å½“å‰é˜¶æ®µçš„åˆ¤æ–­" },
                multiCardContent: { type: Type.ARRAY, items: {
                    type: Type.OBJECT, properties: {
                        type: { type: Type.STRING, description: "'link', 'text', 'tool', etc." },
                        data: { type: Type.OBJECT }
                    }
                }}
            }, required: ["title", "insight"]
        };
        break;

    case 3: // RESCUE MODE
      prompt = `ä½ æ˜¯ä¸€ä¸ªâ€œæ•‘æ´æ¨¡å¼â€AIã€‚ç”¨æˆ·å¯èƒ½åœ¨ä»»åŠ¡â€œ${userContext.task}â€ä¸­é‡åˆ°äº†å›°éš¾ï¼Œå› ä¸ºä»–ä»¬é•¿æ—¶é—´å…³æ³¨åŒä¸€åŒºåŸŸã€‚åˆ†æå›°å¢ƒå¹¶æä¾›ä¸€ä¸ªå…·ä½“çš„è§£å†³æ–¹æ¡ˆç½‘ç«™é“¾æ¥ã€‚`;
      responseSchema = {
          type: Type.OBJECT, properties: {
            title: { type: Type.STRING, description: "ç–‘é—®å¥æ ‡é¢˜ + Emoji" },
            insight: { type: Type.STRING, description: "å›°å¢ƒåˆ†æ (30å­—å†…)" },
            linkCard: { type: Type.OBJECT, properties: {
                    title: { type: Type.STRING }, url: { type: Type.STRING }, description: { type: Type.STRING }
            }, required: ["title", "url", "description"]}
          }, required: ["title", "insight", "linkCard"]
      };
      break;

    default: // MODE 4: EXPLORE
      prompt = `ä½ æ˜¯ä¸€ä¸ªâ€œæ¢ç´¢æ¨¡å¼â€AIã€‚ç”¨æˆ·å¯èƒ½æ„Ÿåˆ°æ— èŠã€‚æ ¹æ®ä»–ä»¬çš„å…´è¶£â€œ${userContext.preferences}â€å’Œå½“å‰å…³æ³¨çš„ç„¦ç‚¹ï¼ŒæŒ–æ˜ä¸€äº›æ·±åº¦çš„ä¿¡æ¯æˆ–æœ‰è¶£çš„æ¢ç´¢ç‚¹ã€‚`;
      responseSchema = {
          type: Type.OBJECT, properties: {
            title: { type: Type.STRING, description: "å¸¦Emojiçš„çŸ­æ ‡é¢˜" },
            insight: { type: Type.STRING, description: "æ´å¯Ÿåˆ†æ (30å­—ä»¥å†…)" },
            recommendations: { type: Type.ARRAY, items: { type: Type.STRING }, description: "æ¢ç´¢é€‰é¡¹åˆ—è¡¨" }
          }, required: ["title", "insight", "recommendations"]
      };
      break;
  }
  
  parts[0].text = prompt;

  try {
    const response = await ai.models.generateContent({
      model: MODEL_NAME,
      contents: { parts },
      config: { responseMimeType: "application/json", responseSchema }
    });

    if (response.text) {
      return JSON.parse(response.text) as StructuredResponse;
    }
    throw new Error("No response text");

  } catch (error) {
    console.error("Gemini Analysis Failed:", error);
    return { title: "âš ï¸ åˆ†æä¸­æ–­", insight: "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡ã€‚", recommendations: ["è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"] };
  }
};

export const chatWithContext = async (
  history: { role: string, parts: any[] }[],
  newMessage: string
): Promise<string> => {
  const prompt = `ç”¨æˆ·è¯´: "${newMessage}"ã€‚åŸºäºä¸Šä¸‹æ–‡å›ç­”ï¼Œå¹¶ä»¥ç»“æ„åŒ–JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å« title, insight, å’Œ recommendations/linkCard/multiCardContent ä¹‹ä¸€ã€‚`;

  try {
    const response = await ai.models.generateContent({
      model: MODEL_NAME,
      contents: [
        ...history.map(h => ({ role: h.role, parts: h.parts })),
        { role: 'user', parts: [{ text: prompt }] }
      ],
      config: { responseMimeType: "application/json" }
    });
    return response.text || "{}";
  } catch (e) {
    return JSON.stringify({ title: "âš ï¸ é”™è¯¯", insight: "å¤„ç†è¯­éŸ³è¯·æ±‚æ—¶å‡ºé”™ã€‚", recommendations: [] });
  }
};